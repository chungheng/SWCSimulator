{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using cuDNN version 5105 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 1080 (0000:01:00.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning evaluation...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 500L, 11L)         44        \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 500L, 256)         143360    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500L, 6L)          1542      \n",
      "=================================================================\n",
      "Total params: 144,946\n",
      "Trainable params: 144,924\n",
      "Non-trainable params: 22\n",
      "_________________________________________________________________\n",
      "Train on 750 samples, validate on 250 samples\n",
      "Epoch 1/5000\n",
      "750/750 [==============================] - 2s - loss: 4330.5996 - val_loss: 4202.3506\n",
      "Epoch 2/5000\n",
      "750/750 [==============================] - 1s - loss: 4323.1348 - val_loss: 4180.3403\n",
      "Epoch 3/5000\n",
      "750/750 [==============================] - 1s - loss: 4314.4893 - val_loss: 4158.1426\n",
      "Epoch 4/5000\n",
      "750/750 [==============================] - 1s - loss: 4301.7025 - val_loss: 4128.5601\n",
      "Epoch 5/5000\n",
      "750/750 [==============================] - 1s - loss: 4278.8633 - val_loss: 4096.3306\n",
      "Epoch 6/5000\n",
      "750/750 [==============================] - 1s - loss: 4229.5435 - val_loss: 4063.0872\n",
      "Epoch 7/5000\n",
      "750/750 [==============================] - 1s - loss: 4125.8717 - val_loss: 4017.5520\n",
      "Epoch 8/5000\n",
      "750/750 [==============================] - 1s - loss: 3968.2027 - val_loss: 3969.5339\n",
      "Epoch 9/5000\n",
      "750/750 [==============================] - 1s - loss: 3825.3687 - val_loss: 3919.9089\n",
      "Epoch 10/5000\n",
      "750/750 [==============================] - 1s - loss: 3714.5020 - val_loss: 3864.0503\n",
      "Epoch 11/5000\n",
      "750/750 [==============================] - 1s - loss: 3610.2452 - val_loss: 3802.7222\n",
      "Epoch 12/5000\n",
      "750/750 [==============================] - 1s - loss: 3503.2729 - val_loss: 3719.2734\n",
      "Epoch 13/5000\n",
      "750/750 [==============================] - 1s - loss: 3386.4388 - val_loss: 3619.5142\n",
      "Epoch 14/5000\n",
      "750/750 [==============================] - 1s - loss: 3254.4018 - val_loss: 3475.4370\n",
      "Epoch 15/5000\n",
      "750/750 [==============================] - 1s - loss: 3114.3529 - val_loss: 3322.4780\n",
      "Epoch 16/5000\n",
      "750/750 [==============================] - 1s - loss: 2988.6512 - val_loss: 3163.1208\n",
      "Epoch 17/5000\n",
      "750/750 [==============================] - 1s - loss: 2890.5705 - val_loss: 3010.4099\n",
      "Epoch 18/5000\n",
      "750/750 [==============================] - 1s - loss: 2812.2756 - val_loss: 2850.1328\n",
      "Epoch 19/5000\n",
      "750/750 [==============================] - 1s - loss: 2744.7233 - val_loss: 2726.5044\n",
      "Epoch 20/5000\n",
      "750/750 [==============================] - 1s - loss: 2682.3840 - val_loss: 2630.5979\n",
      "Epoch 21/5000\n",
      "750/750 [==============================] - 1s - loss: 2623.1882 - val_loss: 2546.8206\n",
      "Epoch 22/5000\n",
      "750/750 [==============================] - 1s - loss: 2566.1088 - val_loss: 2474.7485\n",
      "Epoch 23/5000\n",
      "750/750 [==============================] - 1s - loss: 2510.8113 - val_loss: 2411.7573\n",
      "Epoch 24/5000\n",
      "750/750 [==============================] - 1s - loss: 2456.9475 - val_loss: 2352.8977\n",
      "Epoch 25/5000\n",
      "750/750 [==============================] - 1s - loss: 2404.3924 - val_loss: 2297.0955\n",
      "Epoch 26/5000\n",
      "750/750 [==============================] - 1s - loss: 2353.0028 - val_loss: 2243.7651\n",
      "Epoch 27/5000\n",
      "750/750 [==============================] - 1s - loss: 2303.0999 - val_loss: 2192.5249\n",
      "Epoch 28/5000\n",
      "750/750 [==============================] - 1s - loss: 2254.3652 - val_loss: 2143.2112\n",
      "Epoch 29/5000\n",
      "750/750 [==============================] - 1s - loss: 2206.9976 - val_loss: 2095.5806\n",
      "Epoch 30/5000\n",
      "750/750 [==============================] - 1s - loss: 2160.7829 - val_loss: 2049.4751\n",
      "Epoch 31/5000\n",
      "750/750 [==============================] - 1s - loss: 2115.5355 - val_loss: 2004.8113\n",
      "Epoch 32/5000\n",
      "750/750 [==============================] - 1s - loss: 2071.5674 - val_loss: 1961.5082\n",
      "Epoch 33/5000\n",
      "750/750 [==============================] - 1s - loss: 2028.6862 - val_loss: 1919.4866\n",
      "Epoch 34/5000\n",
      "750/750 [==============================] - 1s - loss: 1986.8814 - val_loss: 1878.6497\n",
      "Epoch 35/5000\n",
      "750/750 [==============================] - 1s - loss: 1946.0778 - val_loss: 1838.9039\n",
      "Epoch 36/5000\n",
      "750/750 [==============================] - 1s - loss: 1906.3709 - val_loss: 1800.1711\n",
      "Epoch 37/5000\n",
      "750/750 [==============================] - 1s - loss: 1867.6002 - val_loss: 1762.4156\n",
      "Epoch 38/5000\n",
      "750/750 [==============================] - 1s - loss: 1829.7325 - val_loss: 1725.6021\n",
      "Epoch 39/5000\n",
      "750/750 [==============================] - 1s - loss: 1792.7657 - val_loss: 1689.6943\n",
      "Epoch 40/5000\n",
      "750/750 [==============================] - 1s - loss: 1756.6297 - val_loss: 1654.6575\n",
      "Epoch 41/5000\n",
      "750/750 [==============================] - 1s - loss: 1721.4576 - val_loss: 1620.4532\n",
      "Epoch 42/5000\n",
      "750/750 [==============================] - 1s - loss: 1686.9701 - val_loss: 1587.0708\n",
      "Epoch 43/5000\n",
      "750/750 [==============================] - 1s - loss: 1653.2774 - val_loss: 1554.4691\n",
      "Epoch 44/5000\n",
      "750/750 [==============================] - 1s - loss: 1620.3869 - val_loss: 1522.6136\n",
      "Epoch 45/5000\n",
      "750/750 [==============================] - 1s - loss: 1588.2381 - val_loss: 1491.4824\n",
      "Epoch 46/5000\n",
      "750/750 [==============================] - 1s - loss: 1556.8392 - val_loss: 1461.0576\n",
      "Epoch 47/5000\n",
      "750/750 [==============================] - 1s - loss: 1526.0903 - val_loss: 1431.3257\n",
      "Epoch 48/5000\n",
      "750/750 [==============================] - 1s - loss: 1495.9354 - val_loss: 1402.2684\n",
      "Epoch 49/5000\n",
      "750/750 [==============================] - 1s - loss: 1466.5510 - val_loss: 1373.8419\n",
      "Epoch 50/5000\n",
      "750/750 [==============================] - 1s - loss: 1437.7639 - val_loss: 1346.0405\n",
      "Epoch 51/5000\n",
      "750/750 [==============================] - 1s - loss: 1409.5457 - val_loss: 1318.8489\n",
      "Epoch 52/5000\n",
      "750/750 [==============================] - 1s - loss: 1381.9687 - val_loss: 1292.2399\n",
      "Epoch 53/5000\n",
      "750/750 [==============================] - 1s - loss: 1354.9829 - val_loss: 1266.2007\n",
      "Epoch 54/5000\n",
      "750/750 [==============================] - 1s - loss: 1328.5808 - val_loss: 1240.7256\n",
      "Epoch 55/5000\n",
      "750/750 [==============================] - 1s - loss: 1302.6661 - val_loss: 1215.8083\n",
      "Epoch 56/5000\n",
      "750/750 [==============================] - 1s - loss: 1277.2769 - val_loss: 1191.4258\n",
      "Epoch 57/5000\n",
      "750/750 [==============================] - 1s - loss: 1252.5062 - val_loss: 1167.5530\n",
      "Epoch 58/5000\n",
      "750/750 [==============================] - 1s - loss: 1228.1907 - val_loss: 1144.1912\n",
      "Epoch 59/5000\n",
      "750/750 [==============================] - 1s - loss: 1204.3686 - val_loss: 1121.3231\n",
      "Epoch 60/5000\n",
      "750/750 [==============================] - 1s - loss: 1181.0726 - val_loss: 1098.9336\n",
      "Epoch 61/5000\n",
      "750/750 [==============================] - 1s - loss: 1158.2286 - val_loss: 1077.0171\n",
      "Epoch 62/5000\n",
      "750/750 [==============================] - 1s - loss: 1135.8352 - val_loss: 1055.5629\n",
      "Epoch 63/5000\n",
      "750/750 [==============================] - 1s - loss: 1113.8792 - val_loss: 1034.5558\n",
      "Epoch 64/5000\n",
      "750/750 [==============================] - 1s - loss: 1092.4849 - val_loss: 1013.9743\n",
      "Epoch 65/5000\n",
      "750/750 [==============================] - 1s - loss: 1071.4128 - val_loss: 993.8355\n",
      "Epoch 66/5000\n",
      "750/750 [==============================] - 1s - loss: 1050.7980 - val_loss: 974.1179\n",
      "Epoch 67/5000\n",
      "750/750 [==============================] - 1s - loss: 1030.6018 - val_loss: 954.8123\n",
      "Epoch 68/5000\n",
      "750/750 [==============================] - 1s - loss: 1010.8023 - val_loss: 935.9116\n",
      "Epoch 69/5000\n",
      "750/750 [==============================] - 1s - loss: 991.4256 - val_loss: 917.4023\n",
      "Epoch 70/5000\n",
      "750/750 [==============================] - 1s - loss: 972.4314 - val_loss: 899.2769\n",
      "Epoch 71/5000\n",
      "750/750 [==============================] - 1s - loss: 953.7698 - val_loss: 881.5289\n",
      "Epoch 72/5000\n",
      "750/750 [==============================] - 1s - loss: 935.5183 - val_loss: 864.1367\n",
      "Epoch 73/5000\n",
      "750/750 [==============================] - 1s - loss: 917.6652 - val_loss: 847.0946\n",
      "Epoch 74/5000\n",
      "750/750 [==============================] - 1s - loss: 900.1623 - val_loss: 830.4064\n",
      "Epoch 75/5000\n",
      "750/750 [==============================] - 1s - loss: 882.9631 - val_loss: 814.0730\n",
      "Epoch 76/5000\n",
      "750/750 [==============================] - 1s - loss: 866.1096 - val_loss: 798.0805\n",
      "Epoch 77/5000\n",
      "750/750 [==============================] - 1s - loss: 849.6533 - val_loss: 782.4135\n",
      "Epoch 78/5000\n",
      "750/750 [==============================] - 1s - loss: 833.4787 - val_loss: 767.0773\n",
      "Epoch 79/5000\n",
      "750/750 [==============================] - 1s - loss: 817.6314 - val_loss: 752.0647\n",
      "Epoch 80/5000\n",
      "750/750 [==============================] - 1s - loss: 802.1234 - val_loss: 737.3636\n",
      "Epoch 81/5000\n",
      "750/750 [==============================] - 1s - loss: 786.9241 - val_loss: 722.9682\n",
      "Epoch 82/5000\n",
      "750/750 [==============================] - 1s - loss: 772.0623 - val_loss: 708.8736\n",
      "Epoch 83/5000\n",
      "750/750 [==============================] - 1s - loss: 757.4075 - val_loss: 695.0833\n",
      "Epoch 84/5000\n",
      "750/750 [==============================] - 1s - loss: 743.1403 - val_loss: 681.5734\n",
      "Epoch 85/5000\n",
      "750/750 [==============================] - 1s - loss: 729.1140 - val_loss: 668.3472\n",
      "Epoch 86/5000\n",
      "750/750 [==============================] - 1s - loss: 715.3791 - val_loss: 655.3954\n",
      "Epoch 87/5000\n",
      "750/750 [==============================] - 1s - loss: 701.8812 - val_loss: 642.7120\n",
      "Epoch 88/5000\n",
      "750/750 [==============================] - 1s - loss: 688.7282 - val_loss: 630.2820\n",
      "Epoch 89/5000\n",
      "750/750 [==============================] - 1s - loss: 675.7916 - val_loss: 618.1144\n",
      "Epoch 90/5000\n",
      "750/750 [==============================] - 1s - loss: 663.1193 - val_loss: 606.2001\n",
      "Epoch 91/5000\n",
      "750/750 [==============================] - 1s - loss: 650.7061 - val_loss: 594.5360\n",
      "Epoch 92/5000\n",
      "750/750 [==============================] - 1s - loss: 638.5765 - val_loss: 583.1197\n",
      "Epoch 93/5000\n",
      "750/750 [==============================] - 1s - loss: 626.6064 - val_loss: 571.9549\n",
      "Epoch 94/5000\n",
      "750/750 [==============================] - 1s - loss: 614.9862 - val_loss: 561.0240\n",
      "Epoch 95/5000\n",
      "750/750 [==============================] - 1s - loss: 603.4923 - val_loss: 550.3316\n",
      "Epoch 96/5000\n",
      "750/750 [==============================] - 1s - loss: 592.3439 - val_loss: 539.8569\n",
      "Epoch 97/5000\n",
      "750/750 [==============================] - 1s - loss: 581.3515 - val_loss: 529.6090\n",
      "Epoch 98/5000\n",
      "750/750 [==============================] - 1s - loss: 570.6118 - val_loss: 519.5778\n",
      "Epoch 99/5000\n",
      "750/750 [==============================] - 1s - loss: 560.0932 - val_loss: 509.7626\n",
      "Epoch 100/5000\n",
      "750/750 [==============================] - 1s - loss: 549.7967 - val_loss: 500.1589\n",
      "Epoch 101/5000\n",
      "750/750 [==============================] - 1s - loss: 539.6833 - val_loss: 490.7657\n",
      "Epoch 102/5000\n",
      "750/750 [==============================] - 1s - loss: 529.8155 - val_loss: 481.5728\n",
      "Epoch 103/5000\n",
      "750/750 [==============================] - 1s - loss: 520.1294 - val_loss: 472.5812\n",
      "Epoch 104/5000\n",
      "750/750 [==============================] - 1s - loss: 510.6539 - val_loss: 463.7824\n",
      "Epoch 105/5000\n",
      "750/750 [==============================] - 1s - loss: 501.3970 - val_loss: 455.1721\n",
      "Epoch 106/5000\n",
      "750/750 [==============================] - 1s - loss: 492.2835 - val_loss: 446.7535\n",
      "Epoch 107/5000\n",
      "750/750 [==============================] - 1s - loss: 483.3754 - val_loss: 438.5175\n",
      "Epoch 108/5000\n",
      "750/750 [==============================] - 1s - loss: 474.7132 - val_loss: 430.4576\n",
      "Epoch 109/5000\n",
      "750/750 [==============================] - 1s - loss: 466.1678 - val_loss: 422.5797\n",
      "Epoch 110/5000\n",
      "750/750 [==============================] - 1s - loss: 457.8253 - val_loss: 414.8771\n",
      "Epoch 111/5000\n",
      "750/750 [==============================] - 1s - loss: 449.6710 - val_loss: 407.3446\n",
      "Epoch 112/5000\n",
      "750/750 [==============================] - 1s - loss: 441.6575 - val_loss: 399.9825\n",
      "Epoch 113/5000\n",
      "750/750 [==============================] - 1s - loss: 433.8685 - val_loss: 392.7826\n",
      "Epoch 114/5000\n",
      "750/750 [==============================] - 1s - loss: 426.1866 - val_loss: 385.7501\n",
      "Epoch 115/5000\n",
      "750/750 [==============================] - 1s - loss: 418.6690 - val_loss: 378.8726\n",
      "Epoch 116/5000\n",
      "750/750 [==============================] - 1s - loss: 411.3956 - val_loss: 372.1400\n",
      "Epoch 117/5000\n",
      "750/750 [==============================] - 1s - loss: 404.1949 - val_loss: 365.5655\n",
      "Epoch 118/5000\n",
      "750/750 [==============================] - 1s - loss: 397.1708 - val_loss: 359.1377\n",
      "Epoch 119/5000\n",
      "750/750 [==============================] - 1s - loss: 390.3095 - val_loss: 352.8506\n",
      "Epoch 120/5000\n",
      "750/750 [==============================] - 1s - loss: 383.6151 - val_loss: 346.7061\n",
      "Epoch 121/5000\n",
      "750/750 [==============================] - 1s - loss: 377.0235 - val_loss: 340.7075\n",
      "Epoch 122/5000\n",
      "750/750 [==============================] - 1s - loss: 370.6015 - val_loss: 334.8490\n",
      "Epoch 123/5000\n",
      "750/750 [==============================] - 1s - loss: 364.3141 - val_loss: 329.1268\n",
      "Epoch 124/5000\n",
      "750/750 [==============================] - 1s - loss: 358.1609 - val_loss: 323.5352\n",
      "Epoch 125/5000\n",
      "750/750 [==============================] - 1s - loss: 352.1458 - val_loss: 318.0724\n",
      "Epoch 126/5000\n",
      "750/750 [==============================] - 1s - loss: 346.2780 - val_loss: 312.7336\n",
      "Epoch 127/5000\n",
      "750/750 [==============================] - 1s - loss: 340.5515 - val_loss: 307.5204\n",
      "Epoch 128/5000\n",
      "750/750 [==============================] - 1s - loss: 334.9001 - val_loss: 302.4350\n",
      "Epoch 129/5000\n",
      "750/750 [==============================] - 1s - loss: 329.3934 - val_loss: 297.4645\n",
      "Epoch 130/5000\n",
      "750/750 [==============================] - 1s - loss: 324.0561 - val_loss: 292.6093\n",
      "Epoch 131/5000\n",
      "750/750 [==============================] - 1s - loss: 318.7760 - val_loss: 287.8746\n",
      "Epoch 132/5000\n",
      "750/750 [==============================] - 1s - loss: 313.6469 - val_loss: 283.2489\n",
      "Epoch 133/5000\n",
      "750/750 [==============================] - 1s - loss: 308.6410 - val_loss: 278.7332\n",
      "Epoch 134/5000\n",
      "750/750 [==============================] - 1s - loss: 303.7271 - val_loss: 274.3279\n",
      "Epoch 135/5000\n",
      "750/750 [==============================] - 1s - loss: 298.9296 - val_loss: 270.0265\n",
      "Epoch 136/5000\n",
      "750/750 [==============================] - 1s - loss: 294.2527 - val_loss: 265.8263\n",
      "Epoch 137/5000\n",
      "750/750 [==============================] - 1s - loss: 289.6678 - val_loss: 261.7284\n",
      "Epoch 138/5000\n",
      "750/750 [==============================] - 1s - loss: 285.1961 - val_loss: 257.7307\n",
      "Epoch 139/5000\n",
      "750/750 [==============================] - 1s - loss: 280.8431 - val_loss: 253.8295\n",
      "Epoch 140/5000\n",
      "750/750 [==============================] - 1s - loss: 276.5376 - val_loss: 250.0262\n",
      "Epoch 141/5000\n",
      "750/750 [==============================] - 1s - loss: 272.4001 - val_loss: 246.3125\n",
      "Epoch 142/5000\n",
      "750/750 [==============================] - 1s - loss: 268.3113 - val_loss: 242.6925\n",
      "Epoch 143/5000\n",
      "750/750 [==============================] - 1s - loss: 264.3230 - val_loss: 239.1598\n",
      "Epoch 144/5000\n",
      "750/750 [==============================] - 1s - loss: 260.4597 - val_loss: 235.7144\n",
      "Epoch 145/5000\n",
      "750/750 [==============================] - 1s - loss: 256.6537 - val_loss: 232.3546\n",
      "Epoch 146/5000\n",
      "750/750 [==============================] - 1s - loss: 252.9475 - val_loss: 229.0798\n",
      "Epoch 147/5000\n",
      "750/750 [==============================] - 1s - loss: 249.3153 - val_loss: 225.8925\n",
      "Epoch 148/5000\n",
      "750/750 [==============================] - 1s - loss: 245.7851 - val_loss: 222.7841\n",
      "Epoch 149/5000\n",
      "750/750 [==============================] - 1s - loss: 242.3400 - val_loss: 219.7542\n",
      "Epoch 150/5000\n",
      "750/750 [==============================] - 1s - loss: 238.9884 - val_loss: 216.8025\n",
      "Epoch 151/5000\n",
      "750/750 [==============================] - 1s - loss: 235.6792 - val_loss: 213.9309\n",
      "Epoch 152/5000\n",
      "750/750 [==============================] - 1s - loss: 232.4788 - val_loss: 211.1293\n",
      "Epoch 153/5000\n",
      "750/750 [==============================] - 1s - loss: 229.3394 - val_loss: 208.3983\n",
      "Epoch 154/5000\n",
      "750/750 [==============================] - 1s - loss: 226.3128 - val_loss: 205.7333\n",
      "Epoch 155/5000\n",
      "750/750 [==============================] - 1s - loss: 223.3092 - val_loss: 203.1425\n",
      "Epoch 156/5000\n",
      "750/750 [==============================] - 1s - loss: 220.4058 - val_loss: 200.6201\n",
      "Epoch 157/5000\n",
      "750/750 [==============================] - 1s - loss: 217.5682 - val_loss: 198.1631\n",
      "Epoch 158/5000\n",
      "750/750 [==============================] - 1s - loss: 214.7956 - val_loss: 195.7689\n",
      "Epoch 159/5000\n",
      "750/750 [==============================] - 1s - loss: 212.1088 - val_loss: 193.4349\n",
      "Epoch 160/5000\n",
      "750/750 [==============================] - 1s - loss: 209.4705 - val_loss: 191.1634\n",
      "Epoch 161/5000\n",
      "750/750 [==============================] - 1s - loss: 206.9066 - val_loss: 188.9513\n",
      "Epoch 162/5000\n",
      "750/750 [==============================] - 1s - loss: 204.4100 - val_loss: 186.7941\n",
      "Epoch 163/5000\n",
      "750/750 [==============================] - 1s - loss: 201.9689 - val_loss: 184.6964\n",
      "Epoch 164/5000\n",
      "750/750 [==============================] - 1s - loss: 199.5806 - val_loss: 182.6546\n",
      "Epoch 165/5000\n",
      "750/750 [==============================] - 1s - loss: 197.2756 - val_loss: 180.6684\n",
      "Epoch 166/5000\n",
      "750/750 [==============================] - 1s - loss: 194.9994 - val_loss: 178.7369\n",
      "Epoch 167/5000\n",
      "750/750 [==============================] - 1s - loss: 192.8072 - val_loss: 176.8569\n",
      "Epoch 168/5000\n",
      "750/750 [==============================] - 1s - loss: 190.6572 - val_loss: 175.0310\n",
      "Epoch 169/5000\n",
      "750/750 [==============================] - 1s - loss: 188.5724 - val_loss: 173.2522\n",
      "Epoch 170/5000\n",
      "750/750 [==============================] - 1s - loss: 186.5357 - val_loss: 171.5198\n",
      "Epoch 171/5000\n",
      "750/750 [==============================] - 1s - loss: 184.5321 - val_loss: 169.8357\n",
      "Epoch 172/5000\n",
      "750/750 [==============================] - 1s - loss: 182.6160 - val_loss: 168.1994\n",
      "Epoch 173/5000\n",
      "750/750 [==============================] - 1s - loss: 180.7204 - val_loss: 166.6121\n",
      "Epoch 174/5000\n",
      "750/750 [==============================] - 1s - loss: 178.8811 - val_loss: 165.0695\n",
      "Epoch 175/5000\n",
      "750/750 [==============================] - 1s - loss: 177.1032 - val_loss: 163.5706\n",
      "Epoch 176/5000\n",
      "750/750 [==============================] - 1s - loss: 175.3527 - val_loss: 162.1181\n",
      "Epoch 177/5000\n",
      "750/750 [==============================] - 1s - loss: 173.6593 - val_loss: 160.7038\n",
      "Epoch 178/5000\n",
      "750/750 [==============================] - 1s - loss: 172.0030 - val_loss: 159.3291\n",
      "Epoch 179/5000\n",
      "750/750 [==============================] - 1s - loss: 170.3977 - val_loss: 157.9940\n",
      "Epoch 180/5000\n",
      "750/750 [==============================] - 1s - loss: 168.8271 - val_loss: 156.6973\n",
      "Epoch 181/5000\n",
      "750/750 [==============================] - 1s - loss: 167.3086 - val_loss: 155.4361\n",
      "Epoch 182/5000\n",
      "750/750 [==============================] - 1s - loss: 165.8201 - val_loss: 154.2120\n",
      "Epoch 183/5000\n",
      "750/750 [==============================] - 1s - loss: 164.3702 - val_loss: 153.0228\n",
      "Epoch 184/5000\n",
      "750/750 [==============================] - 1s - loss: 162.9673 - val_loss: 151.8677\n",
      "Epoch 185/5000\n",
      "750/750 [==============================] - 1s - loss: 161.5937 - val_loss: 150.7461\n",
      "Epoch 186/5000\n",
      "750/750 [==============================] - 1s - loss: 160.2652 - val_loss: 149.6606\n",
      "Epoch 187/5000\n",
      "750/750 [==============================] - 1s - loss: 158.9622 - val_loss: 148.6074\n",
      "Epoch 188/5000\n",
      "750/750 [==============================] - 1s - loss: 157.7064 - val_loss: 147.5860\n",
      "Epoch 189/5000\n",
      "750/750 [==============================] - 1s - loss: 156.4683 - val_loss: 146.5968\n",
      "Epoch 190/5000\n",
      "750/750 [==============================] - 1s - loss: 155.2709 - val_loss: 145.6346\n",
      "Epoch 191/5000\n",
      "750/750 [==============================] - 1s - loss: 154.1255 - val_loss: 144.6979\n",
      "Epoch 192/5000\n",
      "750/750 [==============================] - 1s - loss: 152.9828 - val_loss: 143.7910\n",
      "Epoch 193/5000\n",
      "750/750 [==============================] - 1s - loss: 151.8823 - val_loss: 142.9120\n",
      "Epoch 194/5000\n",
      "750/750 [==============================] - 1s - loss: 150.8038 - val_loss: 142.0596\n",
      "Epoch 195/5000\n",
      "750/750 [==============================] - 1s - loss: 149.7677 - val_loss: 141.2307\n",
      "Epoch 196/5000\n",
      "750/750 [==============================] - 1s - loss: 148.7578 - val_loss: 140.4280\n",
      "Epoch 197/5000\n",
      "750/750 [==============================] - 1s - loss: 147.7760 - val_loss: 139.6497\n",
      "Epoch 198/5000\n",
      "750/750 [==============================] - 1s - loss: 146.8210 - val_loss: 138.8962\n",
      "Epoch 199/5000\n",
      "750/750 [==============================] - 1s - loss: 145.8867 - val_loss: 138.1655\n",
      "Epoch 200/5000\n",
      "750/750 [==============================] - 1s - loss: 144.9904 - val_loss: 137.4561\n",
      "Epoch 201/5000\n",
      "750/750 [==============================] - 1s - loss: 144.1074 - val_loss: 136.7696\n",
      "Epoch 202/5000\n",
      "750/750 [==============================] - 1s - loss: 143.2514 - val_loss: 136.1085\n",
      "Epoch 203/5000\n",
      "750/750 [==============================] - 1s - loss: 142.4276 - val_loss: 135.4715\n",
      "Epoch 204/5000\n",
      "750/750 [==============================] - 1s - loss: 141.6307 - val_loss: 134.8519\n",
      "Epoch 205/5000\n",
      "750/750 [==============================] - 1s - loss: 140.8378 - val_loss: 134.2546\n",
      "Epoch 206/5000\n",
      "750/750 [==============================] - 1s - loss: 140.0826 - val_loss: 133.6792\n",
      "Epoch 207/5000\n",
      "750/750 [==============================] - 1s - loss: 139.3438 - val_loss: 133.1222\n",
      "Epoch 208/5000\n",
      "750/750 [==============================] - 1s - loss: 138.6270 - val_loss: 132.5807\n",
      "Epoch 209/5000\n",
      "750/750 [==============================] - 1s - loss: 137.9338 - val_loss: 132.0592\n",
      "Epoch 210/5000\n",
      "750/750 [==============================] - 1s - loss: 137.2552 - val_loss: 131.5542\n",
      "Epoch 211/5000\n",
      "750/750 [==============================] - 1s - loss: 136.5980 - val_loss: 131.0674\n",
      "Epoch 212/5000\n",
      "750/750 [==============================] - 1s - loss: 135.9600 - val_loss: 130.5932\n",
      "Epoch 213/5000\n",
      "750/750 [==============================] - 1s - loss: 135.3471 - val_loss: 130.1392\n",
      "Epoch 214/5000\n",
      "750/750 [==============================] - 1s - loss: 134.7479 - val_loss: 129.6988\n",
      "Epoch 215/5000\n",
      "750/750 [==============================] - 1s - loss: 134.1568 - val_loss: 129.2723\n",
      "Epoch 216/5000\n",
      "750/750 [==============================] - 1s - loss: 133.5974 - val_loss: 128.8619\n",
      "Epoch 217/5000\n",
      "750/750 [==============================] - 1s - loss: 133.0457 - val_loss: 128.4632\n",
      "Epoch 218/5000\n",
      "750/750 [==============================] - 1s - loss: 132.5124 - val_loss: 128.0781\n",
      "Epoch 219/5000\n",
      "750/750 [==============================] - 1s - loss: 132.0019 - val_loss: 127.7037\n",
      "Epoch 220/5000\n",
      "750/750 [==============================] - 1s - loss: 131.5014 - val_loss: 127.3430\n",
      "Epoch 221/5000\n",
      "750/750 [==============================] - 1s - loss: 131.0099 - val_loss: 126.9920\n",
      "Epoch 222/5000\n",
      "750/750 [==============================] - 1s - loss: 130.5358 - val_loss: 126.6529\n",
      "Epoch 223/5000\n",
      "750/750 [==============================] - 1s - loss: 130.0875 - val_loss: 126.3224\n",
      "Epoch 224/5000\n",
      "750/750 [==============================] - 1s - loss: 129.6352 - val_loss: 126.0016\n",
      "Epoch 225/5000\n",
      "750/750 [==============================] - 1s - loss: 129.2020 - val_loss: 125.6915\n",
      "Epoch 226/5000\n",
      "750/750 [==============================] - 1s - loss: 128.7897 - val_loss: 125.3950\n",
      "Epoch 227/5000\n",
      "750/750 [==============================] - 1s - loss: 128.3817 - val_loss: 125.1107\n",
      "Epoch 228/5000\n",
      "750/750 [==============================] - 1s - loss: 127.9870 - val_loss: 124.8357\n",
      "Epoch 229/5000\n",
      "750/750 [==============================] - 1s - loss: 127.6083 - val_loss: 124.5683\n",
      "Epoch 230/5000\n",
      "500/750 [===================>..........] - ETA: 0s - loss: 128.5625"
     ]
    }
   ],
   "source": [
    "from compact_dependencies import *\n",
    "from neuron_compressor import *\n",
    "batch_size = 500\n",
    "epochs = 5000\n",
    "N = 128\n",
    "\n",
    "I = load_large_dataset('I_HHN')\n",
    "V = load_large_dataset('V_HHN')\n",
    "P = load_large_dataset('P_HHN')\n",
    "\n",
    "I = I[:,:,::100]\n",
    "V = V[:,:,::100]\n",
    "\n",
    "I = np.repeat(I, 10, 0)\n",
    "V = np.repeat(V, 10, 0)\n",
    "P = np.repeat(P, 10, 0)\n",
    "\n",
    "P = P.reshape((P.shape[0], P.shape[1], 1))\n",
    "P = np.repeat(P, I.shape[2], 2)\n",
    "\n",
    "print('Beginning evaluation...')\n",
    "metatype = neuron_compressor(hhn_recovery_model(N, np.concatenate([I, V], axis = 1), P), batch_size = batch_size, epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "P = np.repeat(P, I.shape[2], 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100L, 1000L, 6L)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xhat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5e0359d4ad3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetatype\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Y'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mXhat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'matplotlib inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Xhat' is not defined"
     ]
    }
   ],
   "source": [
    "R = np.abs(metatype['Y'] - Xhat)\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(R[0])\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
